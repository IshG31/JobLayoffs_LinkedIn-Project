{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pd.read_csv(\"job_postings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any unused columns (kept primary key)\n",
    "columns_to_remove = [\"pay_period\",\"applies\",\"work_type\",\"original_listed_time\",\"views\",\"job_posting_url\",\"application_url\",\"remote_allowed\",\"application_type\",\"expiry\",\"closed_time\",\"listed_time\",\"posting_domain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cleaned = job.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cleaned = job_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove city names, as our analysis only focuses on the states\n",
    "def remove_city(location):\n",
    "    if ',' in location:\n",
    "        # Split the location into city and state\n",
    "        parts = [part.strip() for part in location.split(',')]\n",
    "        state = parts[-1]  # Take the last part as the state\n",
    "        return state\n",
    "    else:\n",
    "        return location\n",
    "\n",
    "job_cleaned['location'] = job_cleaned['location'].apply(remove_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated the median salary with the rows that do not have a med_salary, but have a max and min\n",
    "def calculate_median_salary(row):\n",
    "    max_salary = row['max_salary']\n",
    "    min_salary = row['min_salary']\n",
    "    med_salary = row['med_salary']\n",
    "\n",
    "    # Check if med_salary is NaN and either max_salary or min_salary is present\n",
    "    if pd.isna(med_salary) and (pd.notna(max_salary) or pd.notna(min_salary)):\n",
    "        # Filter out NaN values and calculate median\n",
    "        valid_salaries = [value for value in [max_salary, min_salary] if pd.notna(value)]\n",
    "\n",
    "        if valid_salaries:\n",
    "            return pd.Series({'med_salary': pd.Series(valid_salaries).median()})\n",
    "        else:\n",
    "            return pd.Series({'med_salary': None})\n",
    "    else:\n",
    "        return pd.Series({'med_salary': med_salary})\n",
    "\n",
    "# Apply the function to each row\n",
    "job_cleaned['med_salary'] = job_cleaned.apply(calculate_median_salary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cleaned = job_cleaned.drop(columns=['max_salary','min_salary',\"skills_desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to match salaries dataset\n",
    "job_cleaned.rename(columns={'title': 'job_title', \"formatted_experience_level\":\"experience_level\",'med_salary':'salary',\"formatted_work_type\":\"work_type\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating buckets\n",
    "BI = job_cleaned[job_cleaned['job_title'].str.contains(\"Business Intelligence|BI\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a bin to be used for the text analysis, which does not use salary\n",
    "BI_text = BI.drop(columns=['salary','currency','compensation_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_text = BI_text.dropna()\n",
    "len(BI_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_sal_jobpost = BI.drop(columns=['experience_level'])\n",
    "BI_sal_jobpost = BI_sal_jobpost.dropna()\n",
    "len(BI_sal_jobpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = job_cleaned[job_cleaned['job_title'].str.contains(\"Data Analyst\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a bin to be used for the text analysis, which does not use salary\n",
    "DA_text = DA.drop(columns=['salary','currency','compensation_type'])\n",
    "DA_text = DA_text.dropna()\n",
    "len(DA_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_sal_jobpost = DA.drop(columns=['experience_level'])\n",
    "DA_sal_jobpost = DA_sal_jobpost.dropna()\n",
    "len(DA_sal_jobpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = job_cleaned[job_cleaned[\"job_title\"].str.contains(\"Data Engineer\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a bin to be used for the text analysis, which does not use salary\n",
    "DE_text = DE.drop(columns=['salary','currency','compensation_type'])\n",
    "DE_text = DE_text.dropna()\n",
    "len(DE_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE = DE.dropna()\n",
    "len(DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_sal_jobpost = DE.drop(columns=['experience_level'])\n",
    "DE_sal_jobpost = DE_sal_jobpost.dropna()\n",
    "len(DE_sal_jobpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA = job_cleaned[job_cleaned[\"job_title\"].str.contains(\"Business Analyst\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a bin to be used for the text analysis, which does not use salary, currency, or compensation type to provide analysis on the skills needed (for the 5 job positions)\n",
    "BA_text = BA.drop(columns=['salary','currency','compensation_type'])\n",
    "BA_text = BA_text.dropna()\n",
    "len(BA_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset that focuses more on the salary, so remove experience_level to ensure we have a sufficient amount of data\n",
    "BA_sal_jobpost = BA.drop(columns=['experience_level'])\n",
    "BA_sal_jobpost = BA_sal_jobpost.dropna()\n",
    "len(BA_sal_jobpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = job_cleaned[job_cleaned[\"job_title\"].str.contains(\"Data Scientist|Data Science|ML|Machine Learning\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a bin to be used for the text analysis, which does not use salary\n",
    "DS_text = DS.drop(columns=['salary','currency','compensation_type'])\n",
    "DS_text = DS_text.dropna()\n",
    "len(DS_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_sal_jobpost = DS.drop(columns=['experience_level'])\n",
    "DS_sal_jobpost = DS_sal_jobpost.dropna()\n",
    "len(DS_sal_jobpost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that all 10 bins have no null values\n",
    "BI_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_sal_jobpost.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_sal_jobpost.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_sal_jobpost.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_sal_jobpost.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_sal_jobpost.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top locations for each bin\n",
    "BI_top_state = BI_sal_jobpost['location'].value_counts().head(3)\n",
    "BI_top_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_top_state = DA_sal_jobpost['location'].value_counts().head(3)\n",
    "DA_top_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_top_state = DS_sal_jobpost['location'].value_counts().head(3)\n",
    "DS_top_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_top_state = BA_sal_jobpost['location'].value_counts().head(3)\n",
    "BA_top_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_top_state = DE_sal_jobpost['location'].value_counts().head(3)\n",
    "DE_top_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
